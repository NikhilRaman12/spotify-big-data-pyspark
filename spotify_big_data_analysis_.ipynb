{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b8ajEHLCo6l5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spotify Million Playlist Project\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "uvs_ZZXsrA79"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45d8ce77"
      },
      "source": [
        "## Spotify Million Playlist Project: PySpark Analysis\n",
        "\n",
        "This notebook demonstrates a comprehensive analysis of the Spotify Million Playlist Dataset using Apache Spark, leveraging PySpark for efficient data processing and analysis on a large scale.\n",
        "\n",
        "**Goal:** To explore the dataset, identify popular tracks, artists, and albums, analyze playlist characteristics, and visualize key insights.\n",
        "\n",
        "**Dataset:** Spotify Million Playlist Dataset (subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "267f100f"
      },
      "source": [
        "### Step 0: Install & Import Libraries\n",
        "\n",
        "Before starting the analysis, we need to install the necessary libraries and import them into our environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e09c49bb",
        "outputId": "58d9fa42-9ef0-4f7c-9cc0-bbf4772b78a9"
      },
      "source": [
        "!pip install pyspark\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, explode, count, desc\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "939120db"
      },
      "source": [
        "**Insight:** This step ensures all required libraries are available and connected to Google Drive to access the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a708c7c"
      },
      "source": [
        "### Step 1: Initialize Spark Session\n",
        "\n",
        "We initialize a Spark session, which is the entry point for any Spark functionality. We name the application for better identification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd892ee5",
        "outputId": "03f1491f-1c5d-4e15-b0c1-d475482685cc"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Spotify Big Data Analysis\").getOrCreate()\n",
        "print(\"Spark session initialized.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63f9b482"
      },
      "source": [
        "**Insight:** A Spark session is successfully initialized, providing the foundation for distributed data processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "057de218"
      },
      "source": [
        "### Step 2: Load Dataset\n",
        "\n",
        "The dataset, which is in JSON format, is loaded into a Spark DataFrame. We then display the schema and a few rows to understand the data structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb5acb42",
        "outputId": "043d6a18-3249-499c-ead8-74784db7fb1d"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
        "\n",
        "# Define schema for Spotify Million Playlist Dataset\n",
        "schema = StructType([\n",
        "    StructField(\"info\", StructType([\n",
        "        StructField(\"num_tracks\", IntegerType(), True),\n",
        "        StructField(\"num_albums\", IntegerType(), True),\n",
        "        StructField(\"num_followers\", IntegerType(), True),\n",
        "        StructField(\"num_edits\", IntegerType(), True),\n",
        "        StructField(\"playlist_name\", StringType(), True),\n",
        "        StructField(\"playlist_id\", IntegerType(), True),\n",
        "    ])),\n",
        "    StructField(\"playlists\", ArrayType(\n",
        "        StructType([\n",
        "            StructField(\"pid\", IntegerType(), True),\n",
        "            StructField(\"name\", StringType(), True),\n",
        "            StructField(\"num_tracks\", IntegerType(), True),\n",
        "            StructField(\"num_albums\", IntegerType(), True),\n",
        "            StructField(\"num_followers\", IntegerType(), True),\n",
        "            StructField(\"tracks\", ArrayType(\n",
        "                StructType([\n",
        "                    StructField(\"track_name\", StringType(), True),\n",
        "                    StructField(\"artist_name\", StringType(), True),\n",
        "                    StructField(\"album_name\", StringType(), True),\n",
        "                    StructField(\"duration_ms\", IntegerType(), True),\n",
        "                    StructField(\"pos\", IntegerType(), True),\n",
        "                ])\n",
        "            ))\n",
        "        ])\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Load dataset using explicit schema\n",
        "data_path = \"/content/drive/MyDrive/data/mpd.slice.*.json\"\n",
        "\n",
        "df = spark.read.schema(schema).json(data_path)\n",
        "\n",
        "print(\"DataFrame schema:\")\n",
        "df.printSchema()\n",
        "print(\"Sample rows:\")\n",
        "df.show(2, truncate=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame schema:\n",
            "root\n",
            " |-- info: struct (nullable = true)\n",
            " |    |-- num_tracks: integer (nullable = true)\n",
            " |    |-- num_albums: integer (nullable = true)\n",
            " |    |-- num_followers: integer (nullable = true)\n",
            " |    |-- num_edits: integer (nullable = true)\n",
            " |    |-- playlist_name: string (nullable = true)\n",
            " |    |-- playlist_id: integer (nullable = true)\n",
            " |-- playlists: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- pid: integer (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |    |    |-- num_tracks: integer (nullable = true)\n",
            " |    |    |-- num_albums: integer (nullable = true)\n",
            " |    |    |-- num_followers: integer (nullable = true)\n",
            " |    |    |-- tracks: array (nullable = true)\n",
            " |    |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |    |-- track_name: string (nullable = true)\n",
            " |    |    |    |    |-- artist_name: string (nullable = true)\n",
            " |    |    |    |    |-- album_name: string (nullable = true)\n",
            " |    |    |    |    |-- duration_ms: integer (nullable = true)\n",
            " |    |    |    |    |-- pos: integer (nullable = true)\n",
            "\n",
            "Sample rows:\n",
            "+----+---------+\n",
            "|info|playlists|\n",
            "+----+---------+\n",
            "|NULL|NULL     |\n",
            "|NULL|NULL     |\n",
            "+----+---------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e16a04c"
      },
      "source": [
        "**Insight:** The JSON dataset containing playlist information is successfully loaded into a Spark DataFrame, showing a nested structure with playlist details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78cf25b1"
      },
      "source": [
        "### Step 3: Explore Playlists\n",
        "\n",
        "We extract the playlist information from the nested structure using the `explode` function. This creates a new DataFrame where each row represents a single playlist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "f97ca363",
        "outputId": "d40aef4d-9f05-477e-ba79-ace3f4f90aca"
      },
      "source": [
        "playlists = df.select(explode(col(\"playlists\")).alias(\"playlist\"))\n",
        "print(\"Playlists DataFrame schema:\")\n",
        "playlists.printSchema()\n",
        "print(\"Sample playlist rows:\")\n",
        "playlists.show(2, truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Playlists DataFrame schema:\n",
            "root\n",
            " |-- playlist: struct (nullable = true)\n",
            " |    |-- pid: integer (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- num_tracks: integer (nullable = true)\n",
            " |    |-- num_albums: integer (nullable = true)\n",
            " |    |-- num_followers: integer (nullable = true)\n",
            " |    |-- tracks: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- track_name: string (nullable = true)\n",
            " |    |    |    |-- artist_name: string (nullable = true)\n",
            " |    |    |    |-- album_name: string (nullable = true)\n",
            " |    |    |    |-- duration_ms: integer (nullable = true)\n",
            " |    |    |    |-- pos: integer (nullable = true)\n",
            "\n",
            "Sample playlist rows:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-668645492.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplaylists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample playlist rows:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplaylists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     def _show_string(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    974\u001b[0m                 )\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_truncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b83eb8e1"
      },
      "source": [
        "**Insight:** The playlists are successfully extracted into a separate DataFrame, which is easier to work with for playlist-level analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60e44fbb"
      },
      "source": [
        "### Step 4: Flatten Tracks\n",
        "\n",
        "We further flatten the structure to extract individual track details from each playlist. This results in a DataFrame where each row represents a track within a playlist, along with its associated playlist ID."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c33502d"
      },
      "source": [
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Explode playlists to get individual tracks\n",
        "playlists = df.select(explode(col(\"playlists\")).alias(\"playlist\"))\n",
        "\n",
        "tracks = playlists.select(\n",
        "    col(\"playlist.pid\").alias(\"pid\"),\n",
        "    explode(col(\"playlist.tracks\")).alias(\"track\")\n",
        ")\n",
        "\n",
        "# Select track-level details\n",
        "tracks = tracks.select(\n",
        "    \"pid\",\n",
        "    col(\"track.track_name\").alias(\"track_name\"),\n",
        "    col(\"track.artist_name\").alias(\"artist_name\"),\n",
        "    col(\"track.album_name\").alias(\"album_name\"),\n",
        "    col(\"track.pos\").alias(\"position\")\n",
        ")\n",
        "\n",
        "print(\"Sample tracks rows:\")\n",
        "tracks.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37597e86"
      },
      "source": [
        "**Insight:** Track details are successfully flattened, creating a dataset ready for analyzing individual tracks and their properties across playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3921958c"
      },
      "source": [
        "### Step 5: Track Counts\n",
        "\n",
        "We count the occurrences of each track across all playlists to identify the most frequent tracks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee5e00ea"
      },
      "source": [
        "from pyspark.sql.functions import col, explode\n",
        "\n",
        "# Step 5: Flatten playlists into track-level DataFrame\n",
        "playlists = df.select(explode(col(\"playlists\")).alias(\"playlist\"))\n",
        "\n",
        "tracks = playlists.select(\n",
        "    col(\"playlist.pid\").alias(\"pid\"),\n",
        "    explode(col(\"playlist.tracks\")).alias(\"track\")\n",
        ")\n",
        "\n",
        "# Extract relevant track details\n",
        "tracks = tracks.select(\n",
        "    \"pid\",\n",
        "    col(\"track.track_name\").alias(\"track_name\"),\n",
        "    col(\"track.artist_name\").alias(\"artist_name\"),\n",
        "    col(\"track.album_name\").alias(\"album_name\"),\n",
        "    col(\"track.pos\").alias(\"position\")\n",
        ")\n",
        "\n",
        "print(\"Sample tracks rows:\")\n",
        "tracks.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee90b2da"
      },
      "source": [
        "**Insight:** The top tracks are identified, revealing the most popular songs across the sampled playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e6a34f9"
      },
      "source": [
        "### Step 6: Artist Counts\n",
        "\n",
        "Similarly, we count the occurrences of each artist across all playlists to identify the most frequent artists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77f97b55"
      },
      "source": [
        "top_artists = tracks.groupBy(\"artist_name\") \\\n",
        "    .agg(count(\"*\").alias(\"count\")) \\\n",
        "    .orderBy(desc(\"count\"))\n",
        "\n",
        "print(\"Top 10 most frequent artists:\")\n",
        "top_artists.show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d609fa6a"
      },
      "source": [
        "**Insight:** The top artists are determined, highlighting the most frequently featured artists in the playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f23bb01"
      },
      "source": [
        "### Step 7: Visualization – Top Tracks\n",
        "\n",
        "We visualize the top 10 most frequent tracks using a bar plot to easily compare their popularity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05aad508"
      },
      "source": [
        "pdf_tracks = top_tracks.limit(10).toPandas()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(x=\"count\", y=\"track_name\", data=pdf_tracks, palette=\"viridis\")\n",
        "plt.title(\"Top 10 Most Frequent Tracks\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fdf3de2"
      },
      "source": [
        "**Insight:** The bar plot clearly shows the relative popularity of the top 10 tracks, providing a visual summary of the most frequent songs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a9d263f"
      },
      "source": [
        "### Step 8: Visualization – Top Artists\n",
        "\n",
        "We visualize the top 10 most frequent artists using a bar plot to compare their frequency in the playlists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b2fa188"
      },
      "source": [
        "pdf_artists = top_artists.limit(10).toPandas()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(x=\"count\", y=\"artist_name\", data=pdf_artists, palette=\"magma\")\n",
        "plt.title(\"Top 10 Most Frequent Artists\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49e72c84"
      },
      "source": [
        "**Insight:** The visualization of top artists quickly reveals which artists have the strongest presence in the dataset's playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62a6f04b"
      },
      "source": [
        "### Step 9: Playlist Size Distribution\n",
        "\n",
        "We analyze the distribution of playlist sizes (number of tracks per playlist) by calculating descriptive statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6500c44"
      },
      "source": [
        "playlist_sizes = playlists.selectExpr(\"size(playlist.tracks) as num_tracks\")\n",
        "\n",
        "print(\"Playlist size distribution statistics:\")\n",
        "playlist_sizes.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9fd5c9"
      },
      "source": [
        "**Insight:** Descriptive statistics of playlist sizes provide an overview of how many tracks playlists typically contain, showing minimum, maximum, average, and standard deviation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8086bab"
      },
      "source": [
        "### Step 10: Visualization – Playlist Size Distribution\n",
        "\n",
        "We visualize the distribution of playlist sizes using a histogram to understand the frequency of different playlist lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5472ff45"
      },
      "source": [
        "pdf_sizes = playlist_sizes.toPandas()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(pdf_sizes[\"num_tracks\"], bins=50, kde=False, color=\"blue\")\n",
        "plt.title(\"Distribution of Playlist Sizes\", fontsize=14)\n",
        "plt.xlabel(\"Number of Tracks\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb667a2a"
      },
      "source": [
        "**Insight:** The histogram illustrates the distribution of playlist lengths, showing that most playlists are relatively short, with fewer very long playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c289148"
      },
      "source": [
        "### Step 11: Most Popular Albums\n",
        "\n",
        "We identify the most frequent albums across all playlists by counting the occurrences of each album."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "244e9c2c"
      },
      "source": [
        "top_albums = tracks.groupBy(\"album_name\") \\\n",
        "    .agg(count(\"*\").alias(\"count\")) \\\n",
        "    .orderBy(desc(\"count\"))\n",
        "\n",
        "print(\"Top 10 most frequent albums:\")\n",
        "top_albums.show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13ed025"
      },
      "source": [
        "**Insight:** The most popular albums are listed, indicating which albums are most frequently included in playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d72544e"
      },
      "source": [
        "### Step 12: Visualization – Top Albums\n",
        "\n",
        "We visualize the top 10 most frequent albums using a bar plot for easy comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc0d1f03"
      },
      "source": [
        "pdf_albums = top_albums.limit(10).toPandas()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.barplot(x=\"count\", y=\"album_name\", data=pdf_albums, palette=\"cubehelix\")\n",
        "plt.title(\"Top 10 Most Frequent Albums\", fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c17ae3ec"
      },
      "source": [
        "**Insight:** The bar plot of top albums provides a visual ranking of the albums that appear most often in the dataset's playlists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f84b047"
      },
      "source": [
        "### Step 13: Unique Tracks & Artists\n",
        "\n",
        "We calculate the total number of unique tracks and artists in the dataset to understand the diversity of the content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef16536b"
      },
      "source": [
        "unique_tracks = tracks.select(\"track_name\").distinct().count()\n",
        "unique_artists = tracks.select(\"artist_name\").distinct().count()\n",
        "\n",
        "print(\"Unique Tracks:\", unique_tracks)\n",
        "print(\"Unique Artists:\", unique_artists)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c40beb6e"
      },
      "source": [
        "**Insight:** The counts of unique tracks and artists reveal the breadth of musical content within the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f9bbf3c"
      },
      "source": [
        "### Step 14: Save Results\n",
        "\n",
        "Finally, we save the analysis results (top tracks, artists, albums, and playlist sizes) as CSV files to a specified output path for future use or sharing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f05de03d"
      },
      "source": [
        "output_path = \"/content/drive/MyDrive/spotify_project/results\"\n",
        "\n",
        "top_tracks.write.mode(\"overwrite\").csv(output_path + \"/top_tracks\")\n",
        "top_artists.write.mode(\"overwrite\").csv(output_path + \"/top_artists\")\n",
        "top_albums.write.mode(\"overwrite\").csv(output_path + \"/top_albums\")\n",
        "playlist_sizes.write.mode(\"overwrite\").csv(output_path + \"/playlist_sizes\")\n",
        "\n",
        "print(\" Results saved successfully at:\", output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a7502ff"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, ArrayType, StringType, IntegerType\n",
        "\n",
        "# Define the schema for the Spotify Million Playlist Project data\n",
        "schema = StructType([\n",
        "    StructField(\"info\", StructType([\n",
        "        StructField(\"generated_on\", IntegerType(), True),\n",
        "        StructField(\"slice\", IntegerType(), True),\n",
        "        StructField(\"version\", IntegerType(), True)\n",
        "    ]), True),\n",
        "    StructField(\"playlists\", ArrayType(StructType([\n",
        "        StructField(\"description\", StringType(), True),\n",
        "        StructField(\"name\", StringType(), True),\n",
        "        StructField(\"num_followers\", IntegerType(), True),\n",
        "        StructField(\"num_edits\", IntegerType(), True),\n",
        "        StructField(\"num_tracks\", IntegerType(), True),\n",
        "        StructField(\"num_albums\", IntegerType(), True),\n",
        "        StructField(\"num_artists\", IntegerType(), True),\n",
        "        StructField(\"duration_ms\", IntegerType(), True),\n",
        "        StructField(\"collaborative\", StringType(), True),\n",
        "        StructField(\"pid\", IntegerType(), True),\n",
        "        StructField(\"tracks\", ArrayType(StructType([\n",
        "            StructField(\"pos\", IntegerType(), True),\n",
        "            StructField(\"artist_name\", StringType(), True),\n",
        "            StructField(\"track_uri\", StringType(), True),\n",
        "            StructField(\"artist_uri\", StringType(), True),\n",
        "            StructField(\"album_uri\", StringType(), True),\n",
        "            StructField(\"track_name\", StringType(), True),\n",
        "            StructField(\"album_name\", StringType(), True),\n",
        "            StructField(\"duration_ms\", IntegerType(), True)\n",
        "        ]), True), True)\n",
        "    ]), True), True)\n",
        "])\n",
        "\n",
        "print(\"Schema defined successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}